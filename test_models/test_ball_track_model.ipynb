{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "26f95000",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import json\n",
    "import os\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras import layers, models\n",
    "from tensorflow.keras.optimizers.schedules import ExponentialDecay\n",
    "import numpy as np\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "1763a059",
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_video_features(video_path):\n",
    "    cap = cv2.VideoCapture(video_path)\n",
    "    #check if video opened successfully\n",
    "    if not cap.isOpened():\n",
    "        raise ValueError(f\"Could not open video file: {video_path}\")\n",
    "    #extract video resolution and fps\n",
    "    width = int(cap.get(cv2.CAP_PROP_FRAME_WIDTH))\n",
    "    height = int(cap.get(cv2.CAP_PROP_FRAME_HEIGHT))\n",
    "    fps = cap.get(cv2.CAP_PROP_FPS)\n",
    "    return cap, width, height, fps\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "6e71741c",
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "Script to take a video and convert it to downsample size and save it\n",
    "The labels in the test files are also downsized\n",
    "'''\n",
    "def process_video_and_labels(video_path, input_json_path, output_video_path, output_json_path, target_size=(320, 220)):\n",
    "    #check if downsampled video exists\n",
    "    #get original video properties\n",
    "    cap, original_width, original_height, fps = extract_video_features(video_path)\n",
    "    # get scaling from original to target size\n",
    "    scale_x = target_size[0] / original_width\n",
    "    scale_y = target_size[1] / original_height\n",
    "    if not os.path.exists(output_video_path):\n",
    "        # Create video writer\n",
    "        fourcc = cv2.VideoWriter_fourcc(*'mp4v')\n",
    "        out = cv2.VideoWriter(output_video_path, fourcc, fps, target_size)\n",
    "        while True:\n",
    "            #extract video frames\n",
    "            ret, frame = cap.read()\n",
    "            if not ret:\n",
    "                break\n",
    "            #resize video frames and write to output video\n",
    "            resized = cv2.resize(frame, target_size)  # target_size is (width, height)\n",
    "            out.write(resized)\n",
    "\n",
    "        out.release()\n",
    "        print(f\"Saved resized video to: {output_video_path}\")\n",
    "    cap.release()\n",
    "    #Check if dowmsampled labels exist\n",
    "    if not os.path.exists(output_json_path):\n",
    "        with open(input_json_path, 'r') as f:\n",
    "            data = json.load(f)\n",
    "\n",
    "        scaled_data = {\n",
    "            frame: None if coords is None else {\n",
    "                \"x\": coords[\"x\"] * scale_x,\n",
    "                \"y\": coords[\"y\"] * scale_y\n",
    "            }\n",
    "            for frame, coords in data.items()\n",
    "        }\n",
    "\n",
    "        with open(output_json_path, 'w') as f:\n",
    "            json.dump(scaled_data, f, indent=4)\n",
    "        print(f\"Saved scaled labels to: {output_json_path}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "093f8126",
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_specific_frames(video_path, frame_indices):\n",
    "    cap = cv2.VideoCapture(video_path)\n",
    "    extracted_frames = {}\n",
    "\n",
    "    if not cap.isOpened():\n",
    "        print(\"Error: Cannot open video.\")\n",
    "        return extracted_frames\n",
    "\n",
    "    for index in frame_indices:\n",
    "        cap.set(cv2.CAP_PROP_POS_FRAMES, index)\n",
    "        success, frame = cap.read()\n",
    "        if success:\n",
    "            extracted_frames[index] = frame\n",
    "        else:\n",
    "            print(f\"Warning: Could not read frame {index}\")\n",
    "\n",
    "    cap.release()\n",
    "    return extracted_frames\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "880c3a56",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_path = \"../models/tracknet_pre_model.keras\"\n",
    "model = tf.keras.models.load_model(model_path, compile = False)\n",
    "lr_scheduler = ExponentialDecay(\n",
    "        initial_learning_rate=0.001,\n",
    "        decay_steps=100,\n",
    "        decay_rate=0.96)\n",
    "optimizer = tf.keras.optimizers.Adam(learning_rate=lr_scheduler)\n",
    "input_shape=(220, 320, 3)\n",
    "inputs = layers.Input(shape=input_shape)\n",
    "outputs = model(inputs)\n",
    "model = tf.keras.Model(inputs, outputs)\n",
    "model.compile(optimizer=optimizer, loss='mean_squared_error', metrics = ['accuracy', \"f1_score\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cad87b60",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(887, 220, 320, 3)\n",
      "(887, 2)\n"
     ]
    }
   ],
   "source": [
    "test_folder = \"../data/test/\"\n",
    "mse_s = []\n",
    "labels = []\n",
    "for i in range(1,8):\n",
    "    video_file = test_folder + f\"test_{i}.mp4\"\n",
    "    output_video_file = test_folder +f\"test_{i}_down.mp4\"\n",
    "    ball_markup = test_folder + f\"test_{i}/ball_markup.json\"\n",
    "    output_ball_mark = test_folder + f\"test_{i}/ball_markup_down.json\"\n",
    "    process_video_and_labels(video_file, ball_markup, output_video_file, output_ball_mark)\n",
    "\n",
    "    with open(output_ball_mark, 'r') as f:\n",
    "        events_data = json.load(f)\n",
    "    frame_nums = list(map(int, events_data.keys()))\n",
    "    frames = extract_specific_frames(output_video_file, frame_nums)\n",
    "\n",
    "\n",
    "    # print(cropped_frames)\n",
    "    event_data = []\n",
    "    for event in events_data.values():\n",
    "        event_data.append(event)\n",
    "\n",
    "    out_frames = []\n",
    "    for frame in frames.values():\n",
    "        out_frames.append(frame)\n",
    "    frames = np.array(out_frames)\n",
    "    outputs= np.array([[point['x'], point['y']] for point in event_data])\n",
    "    print(frames.shape)\n",
    "    print(outputs.shape)\n",
    "    results = model.predict(frames)\n",
    "    print(results.shape)\n",
    "    mse_fn=tf.keras.losses.MeanSquaredError()\n",
    "    mse = mse_fn(outputs, results)\n",
    "    print(\"MSE Score:\", mse)\n",
    "    mse_s.append(mse)\n",
    "    labels.append(f\"Video {i}\")\n",
    "\n",
    "\n",
    "\n",
    "  \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e7fda56d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Create the bar chart\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.bar(labels, mse_s, color='skyblue')\n",
    "\n",
    "# Add title and labels\n",
    "plt.title('Ball Events Accuracy')\n",
    "plt.xlabel('Video Number')\n",
    "plt.ylabel('Accuracy')\n",
    "\n",
    "# Optionally add grid and display\n",
    "plt.grid(axis='y', linestyle='--', alpha=0.7)\n",
    "\n",
    "# Show the plot\n",
    "plt.show()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "TableTennisUmpire",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
