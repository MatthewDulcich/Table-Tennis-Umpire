{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "26f95000",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import json\n",
    "import os\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras import layers, models\n",
    "from tensorflow.keras.optimizers.schedules import ExponentialDecay\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "1763a059",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_frames_set(ball_json, event_json):\n",
    "    #open ball positions\n",
    "    with open(ball_json, 'r') as f:\n",
    "        ball_data = json.load(f)\n",
    "    #open event positions and transform classes to model output value\n",
    "    with open(event_json, 'r') as f:\n",
    "        events = {\"bounce\": np.array([1,0,0]), \"net\": np.array([0,1,0]), \"empty_event\": np.array([0,0,1])}\n",
    "        event_data = json.load(f)\n",
    "        event_data = {frame: events[event] for frame, event in event_data.items()}\n",
    "    #find intersection b/w keys of ball and event data \n",
    "    #commonality acts as the training set\n",
    "    train_frames = set(event_data.keys()) & set(ball_data.keys())\n",
    "    ball_data = {frame: ball_data[frame] for frame in train_frames}\n",
    "    event_data = {frame: event_data[frame] for frame in train_frames}\n",
    "    print(f\"Train frames: {len(train_frames)}\")\n",
    "    print(f\"Ball data: {len(ball_data)}\")\n",
    "    print(f\"Event data: {len(event_data)}\")\n",
    "    return train_frames, ball_data, event_data\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "6e71741c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def crop_centered_with_padding(image, center, crop_size):\n",
    "    img_h, img_w = image.shape[:2]\n",
    "    crop_w, crop_h = crop_size\n",
    "    cx, cy = center\n",
    "\n",
    "    # Calculate crop box coordinates\n",
    "    x1 = int(cx - crop_w // 2)\n",
    "    y1 = int(cy - crop_h // 2)\n",
    "    x2 = x1 + crop_w\n",
    "    y2 = y1 + crop_h\n",
    "\n",
    "    # Determine padding if crop box is outside image boundaries\n",
    "    pad_left = max(0, -x1)\n",
    "    pad_top = max(0, -y1)\n",
    "    pad_right = max(0, x2 - img_w)\n",
    "    pad_bottom = max(0, y2 - img_h)\n",
    "\n",
    "    # Adjust crop box to fit inside image boundaries\n",
    "    x1 = max(0, x1)\n",
    "    y1 = max(0, y1)\n",
    "    x2 = min(img_w, x2)\n",
    "    y2 = min(img_h, y2)\n",
    "\n",
    "    # Crop the valid region\n",
    "    cropped = image[y1:y2, x1:x2]\n",
    "\n",
    "    # Pad to maintain the same size\n",
    "    cropped_padded = cv2.copyMakeBorder(\n",
    "        cropped,\n",
    "        pad_top, pad_bottom,\n",
    "        pad_left, pad_right,\n",
    "        borderType=cv2.BORDER_CONSTANT,\n",
    "        value=[0, 0, 0]  # black padding\n",
    "    )\n",
    "\n",
    "    return cropped_padded\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "093f8126",
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_specific_frames(video_path, frame_indices):\n",
    "    cap = cv2.VideoCapture(video_path)\n",
    "    extracted_frames = {}\n",
    "\n",
    "    if not cap.isOpened():\n",
    "        print(\"Error: Cannot open video.\")\n",
    "        return extracted_frames\n",
    "\n",
    "    for index in frame_indices:\n",
    "        cap.set(cv2.CAP_PROP_POS_FRAMES, index)\n",
    "        success, frame = cap.read()\n",
    "        if success:\n",
    "            extracted_frames[index] = frame\n",
    "        else:\n",
    "            print(f\"Warning: Could not read frame {index}\")\n",
    "\n",
    "    cap.release()\n",
    "    return extracted_frames\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "37604624",
   "metadata": {},
   "outputs": [],
   "source": [
    "def data_preprocess(video_path, ball_json, event_json):\n",
    "    # Step 1: Get frames set\n",
    "    train_frames, ball_data, event_data = get_frames_set(ball_json, event_json)\n",
    "    \n",
    "    train_frames = list(map(int, event_data.keys()))\n",
    "    print(\"HERE ARE THE TRAIN FRAMES\")\n",
    "    #print(train_frames)\n",
    "    frames = extract_specific_frames(video_path, train_frames)\n",
    "    # Step 3: Center crop frames\n",
    "    cropped_frames = []\n",
    "    for frame in frames:\n",
    "        frame_num = str(frame)\n",
    "        center = (int(ball_data[frame_num]['x']), int(ball_data[frame_num]['y']))\n",
    "        cropped_frame = crop_centered_with_padding(frames[frame], center, (320, 220))\n",
    "        cropped_frames.append(cropped_frame)\n",
    "    print(\"Frames all cropped around ball coordinate\")\n",
    "    return cropped_frames, ball_data, event_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "880c3a56",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_path = \"../models/ball_event_model.keras\"\n",
    "model = tf.keras.models.load_model(model_path, compile = False)\n",
    "lr_scheduler = ExponentialDecay(\n",
    "        initial_learning_rate=0.001,\n",
    "        decay_steps=100,\n",
    "        decay_rate=0.96)\n",
    "optimizer = tf.keras.optimizers.Adam(learning_rate=lr_scheduler)\n",
    "input_shape=(220, 320, 3)\n",
    "inputs = layers.Input(shape=input_shape)\n",
    "outputs = model(inputs)\n",
    "model = tf.keras.Model(inputs, outputs)\n",
    "model.compile(optimizer=optimizer, loss='mean_squared_error', metrics = ['accuracy', \"f1_score\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cad87b60",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train frames: 63\n",
      "Ball data: 63\n",
      "Event data: 63\n",
      "HERE ARE THE TRAIN FRAMES\n",
      "Frames all cropped around ball coordinate\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m68s\u001b[0m 31s/step\n",
      "Accuracy: 0.41269842\n",
      "Train frames: 80\n",
      "Ball data: 80\n",
      "Event data: 80\n",
      "HERE ARE THE TRAIN FRAMES\n",
      "Frames all cropped around ball coordinate\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m82s\u001b[0m 25s/step\n",
      "Accuracy: 0.475\n",
      "Train frames: 55\n",
      "Ball data: 55\n",
      "Event data: 55\n",
      "HERE ARE THE TRAIN FRAMES\n",
      "Frames all cropped around ball coordinate\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m56s\u001b[0m 24s/step\n",
      "Accuracy: 0.43636364\n"
     ]
    }
   ],
   "source": [
    "test_folder = \"../data/test/\"\n",
    "accuracies = []\n",
    "labels = []\n",
    "for i in range(1,8):\n",
    "    if i !=4:\n",
    "        video_file = test_folder + f\"test_{i}.mp4\"\n",
    "        ball_markup = test_folder + f\"test_{i}/ball_markup.json\"\n",
    "        events_markup = test_folder +f\"test_{i}/events_markup.json\"\n",
    "        cropped_frames, ball_data, events_data = data_preprocess(video_file, ball_markup, events_markup)\n",
    "        # print(cropped_frames)\n",
    "        event_data = []\n",
    "        for event in events_data.values():\n",
    "            event_data.append(event)\n",
    "        cropped_frames = np.array(cropped_frames)\n",
    "        outputs = np.array(event_data)\n",
    "        results = model.predict(cropped_frames)\n",
    "        arg_out = tf.argmax(outputs, axis =1)\n",
    "        \n",
    "        y_pred_classes = tf.argmax(results, axis=1)\n",
    "\n",
    "        # Compute accuracy\n",
    "        accuracy = tf.reduce_mean(tf.cast(tf.equal(arg_out, y_pred_classes), tf.float32))\n",
    "        accuracies.append(accuracy)\n",
    "        labels.append(f\"Video {i}\")\n",
    "        print(\"Accuracy:\", accuracy.numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d0534112",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Create the bar chart\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.bar(labels, accuracies, color='skyblue')\n",
    "\n",
    "# Add title and labels\n",
    "plt.title('Ball Events Accuracy')\n",
    "plt.xlabel('Video Number')\n",
    "plt.ylabel('Accuracy')\n",
    "\n",
    "# Optionally add grid and display\n",
    "plt.grid(axis='y', linestyle='--', alpha=0.7)\n",
    "\n",
    "# Show the plot\n",
    "plt.show()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "TableTennisUmpire",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
